\input{chapter-header.tex}
% ===========================================================================
\part{State of the Art}
% ===========================================================================

%Software inevitable changes and we need to provide with the tools and methodologies that support such changes~\cite{Nier08b}. However, production-ready applications are not usually change-aware. These applications should be either engineered from scratch with change in mind, or a lot of reengineering effort should be invested in them to support change. Making deep modifications to a language runtime can be a cumbersome task.

% ===========================================================================
%\newpage
% ===========================================================================

\chapter{Application Runtime Manipulation}
\chaplabel{state_modifying}
\minitoc

Generating an application runtime requires the basic ability to manipulate such runtime \eg create and modify classes and methods; instantiate objects; begin and stop threads in it. This chapter explores the state of the art on application runtime manipulation. We identify three main concerns that arise when we attempt to modify an application runtime~(Section \ref{sec:bootstrapping_problems}): how easily a change can be applied to a language runtime, how coupled are the application runtime and \VM concerns, and what is the existing tool support to modify such application runtime.

Based on those concerns, we created an evaluation criteria for application runtime manipulation solutions~(Section \ref{sec:runtime_modification_criteria}). Finally, we present different techniques for application runtime manipulation and we compare the most relevant of them with our criteria:

\begin{description}

\item[Reflection models.] The literature presents several language runtime manipulation solutions based on metaprogramming and \emph{reflection}~(Section \ref{sec:related_work_changing}). These metaprogramming models allow either the modification of the language interpreter semantics or the scoping of modifications with one main objective: performing such modifications safely \ie avoid breaking the application runtime they are running on.

\item[Metacircular runtimes.] Metacircular runtimes aim at easing the modification of a runtime by means of simplifying the language-\VM relation for development~(Section \ref{sec:metacircular_runtimes}). This simplification comes usually by expressing a \VM in the same language it interprets at the end. Metacircular \VMs focus on the simplification of complexity in \VM technology and does not focus on the manipulation of the language runtime elements.

\item[Virtualization techniques.] Virtualization techniques applied to application runtimes are used for application control and manipulation~(Section \ref{sec:background_virtualization_techniques}). Application co-existence allows the modification of an application without affecting others. Application manipulation provides with control on an application's life cycle and its internal representation.

\end{description}

\section{Concerns of Application Runtime Manipulation} \label{sec:bootstrapping_problems}

We identify three main challenges when we aim at changing an application runtime. First, how flexible its language runtime is to be changed and adapted without running into inconsistent states. Second, the unclear mixture of \VM and language concerns prevents us to extract the language concerns to easily replace them. Finally, the differences in the abstraction levels and tool support between the application runtime we manipulate and the tools we use for it makes it a challenging task.


\subsection{Flexibility to Safely Change a Language Runtime}

The \VM is often the component in charge of initializing the application runtime and particularly the language runtime. This decision is indeed practical as the \VM can safely initialize the language structures and solve the language bootstrapping issues avoiding recursions~\cite{Kicz91a}~(\eg create the first class without a class). This application runtime must comply at runtime to the execution model imposed by the \VM. This coupling is indeed necessary to run a program but does often remain hidden in hardcoded assumptions, presenting two main consequences. First, the \VM fixes the initial structures of the language runtime. For example, Ruby's initial class hierarchy is imprinted inside the \VM code fixing with \ct{BasicObject} as the top superclass and followed by \ct{Object}, \ct{Module} and \ct{Class} respectively~(Figure \ref{code:ruby_hierarchy}).

\begin{figure}[ht!]
\begin{code}
void Init_class_hierarchy(void) {
    rb_cBasicObject = boot_defclass("BasicObject", 0);
    rb_cObject = boot_defclass("Object", rb_cBasicObject);
    rb_cModule = boot_defclass("Module", rb_cObject);
    rb_cClass =  boot_defclass("Class",  rb_cModule);

    rb_const_set(rb_cObject, rb_intern("BasicObject"),rb_cBasicObject);
    RBASIC_SET_CLASS(rb_cClass, rb_cClass);
    RBASIC_SET_CLASS(rb_cModule, rb_cClass);
    RBASIC_SET_CLASS(rb_cObject, rb_cClass);
    RBASIC_SET_CLASS(rb_cBasicObject, rb_cClass);
}
\end{code}
\caption{\textbf{Code of the Ruby VM that initializes the class hierarchy (excerpt).} The VM code fixes the language class hierarchy.\label{code:ruby_hierarchy}}
\end{figure}

Second, the \VM includes code to manipulate language runtime objects introducing a duplication between the \VM code and the language code. To illustrate this problem, let us consider the code at the left of Figure~\ref{code:logic_dup} that creates a \ct{Dictionary} object~(a hash map object). A language runtime that is defined by a \ct{Dictionary} object to keep \eg a map of global objects, must execute the code in the figure to create the corresponding instance during the language initialization. However, since the language runtime and the \VM are in middle of their initialization, the \VM cannot execute this code as it is, and thus it cannot enforce its own invariants. The state of the art production \VMs will provide an alternative low-level representation of the same code respecting the same invariants, exemplified at the right of the same figure. This introduces a redundancy: the \VM and the language have different code to honor the same invariants.

\begin{figure}[ht]
\begin{subfigure}{.5\linewidth}
\begin{code}
Dictionary class>>new: n
    ^ self new initialize: n

Dictionary>>initialize: n
    "Initialize array to an array size of n"
    array := Array new: n.
    tally := 0
\end{code}
\end{subfigure}
\begin{subfigure}{.5\linewidth}
\begin{code}
void* createDictionaryWithSize(int n){
    void* dictionary, internalArray;
    dictionary = instantiate("Dictionary");
    internalArray := instantiate("Array", n);
    setInstanceVariable(dictionary, 1, internalArray);
    setInstanceVariableInt(dictionary, 2, 0);
    return dictionary;
}
\end{code}
\end{subfigure}
\caption{\textbf{Code to create a \ct{Dictionary} object.} To the left, the code is written in Smalltalk. To the right, a function with the similar semantics, but written in C, duplicates this behavior at the \VM level.\label{code:logic_dup}}
\end{figure}


%This execution model is often less restrictive than the object models of the language's that run on top of them. For example, the Smalltalk and Ruby \VMs require for each object in the system to have a class, and each class a superclass, but there is no need for metaclasses.

After the language initialization, reflective languages~\cite{Smit84a} such as LISP or Smalltalk provide means to modify themselves at runtime. These languages are based on a reflective architecture presenting the notion of causal connection~\cite{Maes87a}: a link between a programming element and its representation that keeps both in synchronization. However, as these languages contain meta-circular definitions in their kernel~\cite{Chib96a}, this can result in a Metastability problem~\cite{Kicz91a} \ie a change in the language runtime may introduce a meta-call recursion and turn the system unusable.% In this context, Reflectivity~\cite{Denk08b} is a framework that scopes reflection to avoid meta-call recursions.  Reflectivity succeeds to control behavioural reflection by accounting the level of \emph{metaness} of the execution in a program and executing reflective operations when it is in the correct meta-level. The main limitation of Reflectivity is that it does not allow structural reflective changes in the language runtime.

Finally, snapshot-based languages offer different means to evolve a language runtime. Instead of being reinitialized each time we need it, the state of the whole graph of objects that denotes the running program can be suspended and saved as a snapshot in a file. Later on, the program in this snapshot can be restarted from the point it was suspended. As a consequence of this persistency property, some snapshot-based languages such as Squeak or Pharo  do not have the infrastructure to be reinitialized from scratch. Indeed, their current deliverable snapshots are the result of a chain of side effects (updates and migrations) applied to the original Smalltalk-80 snapshot. Thus, even if we can change the application runtime during execution, they cannot ensure a reproducible initial state for their users.

\subsection{Mixture of \VM and Language Concerns}

The unclear interface between the language and the \VM makes it difficult to recognize whether a piece of code belongs to a \VM or language concern. This causes undesirable temporal couplings between these two elements and prevents us from extracting and replacing the application runtime by another one.
To illustrate this problem, Figure \ref{code:jikes_vm_initialization} shows an excerpt of the JikesRVM\footnote{Taken from the version 3.1.3 of the JikesRVM in \url{http://sourceforge.net/projects/jikesrvm}}~\cite{Alpe00a}. In this example, the memory manager is initialized in the middle of the initial class loading phase. These memory manager calls are indeed needed to avoid the collection of objects during the initialization. However, it is necessary to call it after some specific classes are initialized and not before.

\begin{figure}[ht]
\begin{code}
private static void finishBooting() {
    ...
    MemoryManager.postBoot(); //Memory management
    ...
    runClassInitializer("java.lang.Runtime");
    runClassInitializer("java.lang.System");
    runClassInitializer("sun.misc.Unsafe");
    ...
    MemoryManager.fullyBootedVM(); //Memory management
    ...
    runClassInitializer("java.util.logging.Level");
    runClassInitializer("gnu.java.nio.charset.EncodingHelper");
}
\end{code}
\caption{\textbf{Code of the JikesRVM that initializes loads the initial classes of the runtime (excerpt).} The code performing the initial class loading is mixed with the code that initializes the memory manager of the \VM.\label{code:jikes_vm_initialization}}
\end{figure}

Snapshot-based languages, on the other side, show that language initialization and \VM initialization can be orthogonal. Indeed, languages such as Pharo, LISP or the V8 flavor of Javascript can restart their system from a snapshot. The \VM loads atomically the snapshot and binds it to the current runtime. Loading a snapshot clarifies the \VM startup steps as it replaces the phase of language initialization. Moreover, as long as the snapshot satisfies the \VM execution model, it can run any language model, as it is the case of Pharo and Newspeak that run on the same \VM.

%Other snapshot-based languages such as GNU-Smalltalk or the V8 flavor of Javascript possess both mechanisms: they recreate the language runtime from scratch, and can also restart from a snapshot. In the case of V8, the snapshot was chosen with performance in mind, to avoid parsing and recreation on client-side machines.

%\item[The \VM-Language interface is unclear.]
%For example, the \VM assumes how objects are structured in the runtime to manipulate them: the amount and size of their instance variables, object headers, special kind of object references~(\eg weak references). The \VM also needs access to some well-known objects to run code: this is the case for example of \ct{nil}, \ct{true} and \ct{false} objects. Another example of a tight coupling are the callbacks \VM-language, where the \VM can trigger some specific code on the language to notify it from some event.

\subsection{Abstraction Level and Tool Support}

When defining the language runtime at the \VM level, we rely on the tools and abstractions available to develop the \VM to change the language. That means that the language developer uses often low-level abstractions to express higher-level concerns. This \emph{mismatch} impacts the \VM/language developer efficiency, as the tools are not adequate for the task to accomplish. This problem is indeed aggravated with the complexity of such pieces of software, including elements such as the \GC or the JIT that cross-cut every \VM concern.

Indeed the developer would benefit from the productivity that a high-level language brings. In this sense, reflective languages support naturally the usage of the language abstractions and tools to modify the language runtime. Reflective languages benefit from the reification of the language concepts to be able to change them from the language itself. Languages such as Smalltalk show how debuggers and code browsers can be built using such features\gp{cite}.

%To attack these problems, many programming systems have found desirable to follow the principles of \emph{high-level low-level programming} \ie expressing low-level concerns using high-level languages~\cite{Fram09a}. High-level low-level programming pursues the objective of simplifying the complexity of programming systems. By using a high-level language to describe the low-level world the developer benefits from their abstraction power and tooling of the first one. A clear example of this fact is the metacircular \VM field, where many projects whose goal is to write \VMs in a high-level language have blossomed in the last years~\cite{Wimm13a,Alpe00a,Verw11a,Inga97a,Unga05a,Rigo06a}. These projects are biased to \VM building techniques and not to the initialization of the languages that run on top of them.

\section{Evaluation Criteria}\label{sec:runtime_modification_criteria}

This section presents the features we consider relevant to include in a runtime manipulation solution. These features serve as a criteria to compare the state of the art we selected in the following sections.

\begin{description}

\item[Manipulate Language Elements.] An application runtime manipulation solution must support the creation and modification of elements that conform the language runtime\eg create and modify of classes and methods.
\item[Manipulate Execution Elements.] An application runtime manipulation solution must also provide support to manipulate those elements related to a program's execution\eg the creation, pausing and resumption of threads; the introspection of such threads to understand a program's execution.
\item[Manipulate Objects.] An ideal application runtime manipulation should provide access to objects. It should support class instantiation, and object manipulation.
\item[Safety.] An application runtime manipulation solution should guarantee that both incorrect modifications cannot be applied, and that correct modifications can be safely applied without leaving the system in an inconsistent state.

\item[Users level of abstraction.] Whether the user of an application runtime manipulation solution is written in a high-level or low-level language. A solution available to a high-level language enables its users to benefit from the abstractions and expression power of such language.

\item[API level of abstraction.] The API of an ideal application runtime manipulation solution must provide the abstractions to manipulate the application runtime in terms of the runtime's constructions.

\item[Mixture of concerns.] The solution should clearly separate the interface to modify the application runtime from other concerns such as the \GC or the JIT compiler.

\end{description}

\section{Reflection and Metaprogramming Models}\label{sec:related_work_changing}

\subsection*{\textsc{Tower of Interpreters Model}}

The original model of reflection as defined by Smith~\cite{Smit82c} is based on meta-level interpretation. A program is interpreted by an interpreter, such interpreter is interpreted by a meta-interpreter and so on, possibly ad-infinitum. This leads to a tower of interpreters, where each floor defines the semantics of the program~(interpreter of application) it interprets~(Figure \ref{fig:tower_of_interpreters}).

\begin{figure}[ht]
\begin{center}
\includegraphics[width=.5\linewidth]{tower_of_interpreters}
\caption{\textbf{The theoretical tower of interpreters model.} Each floor interprets the floor below itself.\label{fig:tower_of_interpreters}
% (a)The host language and (b)the guest language contain each one their own classes and objects. The guest language resides inside the host language during the bootstrap; (c)the builder, a program written in the host language, reifies the bootstrap process itself and bootstraps the guest language given a (d)source code specification.
 }
\end{center}
\end{figure}

The tower of interpreters presents a model where one can define and redefine the semantics of the program it is executing. We can modify the behavior of our program~(in the floor zero) by jumping one level above it in the tower and modifying the interpreter running in that floor. In the same sense, we can jump one level above this interpreter to change also its behavior and so on. This allows the \emph{indirect modification} of a program's behavior \ie a change in an interpreter in a level \emph{n} changes the behavior of the interpreter level \emph{n - 1}, which impacts in the interpreter below it and so on, up to the base level.

Smith's tower of interpreters model is flexible and coherent regarding the manipulation of the reflective behavior of a program. The tower does not present a limit on the amount of interpreters we can stack, presenting a problematic infinite potential. This idea collides with the non-infinite amount resources in current hardware. On one side, limited memory prevents us to have a tower of infinite interpreters running at the same time. On the other side, above certain limit of interpreters, this approach becomes too slow and impractical. We will show in the following subsections other reflective models that try to overcome these deficiencies while trying to keep some of the good properties of this model.

\subsection*{\textsc{Black}}

Black is a reflective language based on Scheme that mimics the infinite tower of interpreters with the goal to make it practical. Its model is based on the same idea as the reflective tower: the base level is interpreted by an interpreter, which is interpreted by a meta-interpreter and so on. The main difference between the original tower of interpreters and the model presented by Black is that the latter avoids the infinite regression, making the model practical in finite resource machines.

Black avoids the infinite regression by limiting the real levels of interpretation: there is only one level of interpretation. For the rest of the levels, Black  introduces a difference between directly-executed code in contrast with interpreted code. Directly-executed code is code that is executed by the machine, where no interpretation steps are involved. Then, the base-level application is the only interpreted code in the application. The rest of the tower, including the first interpreter, is implemented and executed directly in machine code~(Figure \ref{fig:black_tower}).

\begin{figure}[ht]
\begin{center}
\includegraphics[width=.6\linewidth]{black_tower}
\caption{\textbf{Black model of interpreters.} Only the application level is interpreted. The levels above are directly executed on the machine.\label{fig:black_tower}
% (a)The host language and (b)the guest language contain each one their own classes and objects. The guest language resides inside the host language during the bootstrap; (c)the builder, a program written in the host language, reifies the bootstrap process itself and bootstraps the guest language given a (d)source code specification.
 }
\end{center}
\end{figure}

By limiting the levels of interpretation, the model presented by Black forbids \emph{indirect modification}. Changing the interpreter in a level \emph{n} above the first level does not impact any more the interpreters below it, as they are directly-executed in the machine and not by the modified interpreter. Black supports, however, the modification of the first level of interpretation with the introduction of hooks inside the machine code. A hook detects whether a function in the interpreter~(written in directly-executed code) is changed, and interprets it by a meta-level interpreter written also in directly executed code. Hooks degrade the performance in comparison of a non-hooked interpreter, but it allows in exchange to change and specialize the behavior of the directly-executed code.

\subsection*{\textsc{Safe-Tcl}}
Safe-Tcl~\cite{Levy97a, Bore94a} is a variation of Tcl whose main purpose is the execution of Tcl scripts in a safe environment, with restricted permissions and attributions. Safe-Tcl achieves this by using \emph{twin interpreters} \ie a normal Tcl interpreter~(the master interpreter) can invoke another interpreter and specialize its behavior. Both the master child interpreters run isolated from each other~(Figure \ref{fig:safetcl_twin_interpreters}).

\begin{figure}[ht]
\begin{center}
\includegraphics[width=.6\linewidth]{safetcl_twin_interpreters}
\caption{\textbf{SafeTcl Twin Interpretation.} The Master interpreter creates and configures a safe interpreter. The safe interpreter, with modified commands, will run the sandboxed Tcl application.\label{fig:safetcl_twin_interpreters}
% (a)The host language and (b)the guest language contain each one their own classes and objects. The guest language resides inside the host language during the bootstrap; (c)the builder, a program written in the host language, reifies the bootstrap process itself and bootstraps the guest language given a (d)source code specification.
 }
\end{center}
\end{figure}

The master interpreter modifies the behavior of a safe interpreter by providing a security policy. A security policy grants or removes privileges to the scripts executed on an interpreter. Commands can be aliased so the untrusted interpreter call an aliased method and the command is fully implemented by a trusted interpreter.

Safe-Tcl twin interpretation allows us to change the behavior of a program running on a specialized interpreter, without the limitations of the infinite tower of interpreters. However, in contrast with the solutions we already presented, Safe-Tcl does not provide with the ability to change completely the semantics of the language but just to override or provide new commands, with a focus on security.

\subsection*{\textsc{Reflectivity: scoping reflection in Reflective Architectures}}

To enable reflection in mainstream languages such as Java, Ruby or JavaScript, the tower of interpreters is replaced by a reflective architecture~\cite{Maes87a}. Instead of relying on a stack of interpreters interpreting each the level below it, a reflective architecture relies on the idea of \emph{causal connection} \ie the programming language incorporates structures that represents aspects of itself~(\eg classes, objects), in such a way that if one structure changes the aspect it represents is updated accordingly, and vice-versa.


In languages presenting reflective architectures, reflection is controlled by meta-objects that live in the same environment of the object it reflects upon.
One problematic corollary of this is that meta-objects rely on the same code and infrastructure than the objects they reflect upon; therefore there is a risk of infinite meta-recursion when the meta-level instruments code that it relies upon~(Figure \ref{fig:reflectivity_meta_recursion}).

\begin{figure}[ht]
\begin{center}
\includegraphics[width=.6\linewidth]{reflectivity_meta_recursion}
\caption{\textbf{Meta level recursion in reflective architectures.}\label{fig:reflectivity_meta_recursion}
% (a)The host language and (b)the guest language contain each one their own classes and objects. The guest language resides inside the host language during the bootstrap; (c)the builder, a program written in the host language, reifies the bootstrap process itself and bootstraps the guest language given a (d)source code specification.
 }
\end{center}
\end{figure}

Denker et al. solve this problem in Reflectivity~\cite{Denk08b}. Reflectivity is a reflective framework that avoids meta-recursions by tracking the degree of metaness of the execution context. In each reflective call, the \ct{MetaContext} object is activated and it accounts the meta-level jump. Likewise, when the reflective call returns, the \ct{MetaContext} is deactivated. Using the accounted meta-level jumps of the \ct{MetaContext}, meta-objects do only reflect on objects of a lower metaness~(and not greater or equal metaness). Thus, it simulates the semantics of an infinite tower of distinct interpreters while there is only one of them~(Figure \ref{fig:reflectivity_avoid_meta_recursion}).

\begin{figure}[ht]
\begin{center}
\begin{subfigure}{.45\textwidth}
\includegraphics[width=1\linewidth]{reflectivity_metaness_accounting}
\end{subfigure}
\begin{subfigure}{.45\textwidth}
\includegraphics[width=1\linewidth]{reflectivity_avoid_recursion}
\end{subfigure}
\caption{\textbf{Meta level jump using reflectivity.}\label{fig:reflectivity_avoid_meta_recursion}
% (a)The host language and (b)the guest language contain each one their own classes and objects. The guest language resides inside the host language during the bootstrap; (c)the builder, a program written in the host language, reifies the bootstrap process itself and bootstraps the guest language given a (d)source code specification.
 }
\end{center}
\end{figure}

Reflectivity succeeds to modify and scope behavioral reflection for different meta-levels inside the same reflective architecture. However, it does not provide with support to fully change the language semantics~(residing in the \VM) or to perform structural reflection.

\section{Metacircular Runtimes and \VMs}\label{sec:metacircular_runtimes}

The increased complexity of the \VMs leads to more novel approaches on how to build \VMs.
Metacircular \VMs are \VMs programmed in the same language they support in the end. This approach, based on the principles of \emph{high-level low-level programming} \ie expressing low-level concerns using high-level languages~\cite{Fram09a}, benefits from the abstraction power and tooling of the high-level language to manipulate their own \VMs. 

We observer that these projects are biased towards \VM building techniques and not to the manipulation of the languages that run on top of them.
In this thesis, even if we do not focus on the modification of \VMs, we briefly study metacircular runtimes and \VMs with the objective of understanding more concretely the benefits of their high-level low-level approach.

\subsection*{\textsc{Squeak Smalltalk \VM}}
\seclabel{background-squeak}
% ---------------------------------------------------------------------------
The Squeak \VM~\cite{Inga97a} is an early metacircular \VM for the Smalltalk language. 
Its core building system is still in active use for the \urlfootnote{Cog \VM}{http://www.mirandabanda.org/cogblog/} which extends Squeak with a JIT compiler.
The Cog \VM is used as default by the \urlfootnote{Pharo}{http://pharo.org/} programming language.
The Squeak \VM is built around a Smalltalk subset called Slang that is exported to C to be compiled to the final \VM binary.
%Additionally, the Slang sources can be interpreted to provide an interactive simulator of the \VM, including full graphical support.

Slang is limited to the functionality that can be expressed with standard C code.
Slang in this case is mostly a high-level C preprocessor.
Even though Slang basically has the same syntax as Smalltalk it is semantically constrained to expressions that can be resolved statically at compilation or code generation time and are compatible with C.
Hence Slang's semantics are closer to C's than to Smalltalk's.
Unlike later metacircular frameworks, Squeak uses little or no compile-time reflection to simplify the \VM designs.
However, class composition help structuring the sources.
Next to the Slang source which account for the biggest part of the interpreter code some operating system related code and plugins are written in C.
To facilitate the interaction with the pure C part Slang supports inline C expressions and type annotations.

A great achievement of the Squeak \VM is a simulator environment that enables programmers to interact dynamically with a simulated version of the running.
The simulator is capable or running a complete Squeak Smalltalk image including graphical user interface.
This means that programmers can change the sources of the running \VM and see the immediate effects in the simulator.
The \VM developer has complete access and control to the \VM internals and the application runtime it contains. It can, for example, change any object and class inside the simulated application runtime. However, to apply such a change it depends on a high-level but memory oriented interface. Additionally, once the \VM is generated, this low-level interface disappears and is not accessible for the developer.

% ---------------------------------------------------------------------------
\subsection*{\textsc{Jikes: High-level low-level Programming with MMTK}}
\seclabel{background-jikes}
% ---------------------------------------------------------------------------
Jikes (former Jalape√±o) is an early metacircular research \VM for Java written in Java~\cite{Alpe00a}.
The Jikes \VM features several different garbage collectors and does not execute bytecodes but directly compiles to native code.
With metacircularity in mind Jikes does not resort to a low-level programming language such as C for these typically low-level \VM components.
Instead they are written in Java as well using a high-level low-level programming framework.

The Jikes \VM had performance as a major goal, hence direct unobstructed interaction with the low-level world is necessary using a specialized framework.
High-level low-level programming \cite{Fram09a} is mentioned the first time in the context of the Jikes \VM project.
The goal of high-level low-level programming is to provide high-level abstractions to simplify low-level programming.
Essentially this is the same motivation that drives the metacircular \VM community.

Frampton et al. present a high-level low-level framework packaged as \ttt{org.vmmagic}, which is used as a system interface for Jikes. This framework introduces highly controlled low-level interaction in a statically type context. This framework provides with a memory-oriented API to manipulate runtime entities at \VM generation time, which is used to implement \VM concerns. Once generated, the interface exposed by the \ttt{org.vmmagic} framework is translated into native code and this interface is not available for the developer.


% ---------------------------------------------------------------------------
\subsection*{\textsc{Maxine Java \VM}}
\seclabel{background-maxine}
% ---------------------------------------------------------------------------
Maxine is a metacircular Java \VM~\cite{Wimm13a} focused on an efficient developer experience.
Typically \VM frameworks focus on abstraction at the code-level which should yield simpler code and thus help reducing development efforts.
However, in most situations the programmer is still forced to use existing unspecific tools for instance to debug the \VM.
In contrast to that, the Maxine \VM provides dedicated tools to interact with the \VM in development.
Maxine uses abstract and high-level representations of \VM-level concepts and consistently exposes them throughout the development process.

The Maxine project follows an approach where reflection is only used at compile-time \ie once the \VM is generated, the metacircular property of the \VM is lost. However, Maxine development tools provide a live interaction with the complete state of the running \VM artifact while debugging it. We believe such a tool support should be available to manipulate a language runtime.

%\subsection*{\textsc{PyPy Toolchain}}
%\seclabel{background-pypy}
%% ---------------------------------------------------------------------------
%\urlfootnote{PyPy}{http://pypy.org/} is a Python-based high-level \VM framework~\cite{Rigo06a}.
%PyPy's major focus lies on an efficient Python interpreter.
%However, it has been successfully used to build \VMs for other languages including Smalltalk~\cite{Bolz08a}.
%Interpreters are written in a type-inferable subset of Python called RPython.
%The underlying PyPy infrastructure automatically provides memory management and JIT compilation.
%Instead of explicitly providing these features, a \VM developer hints certain information to the PyPy framework to improve the generation of a GC or JIT.
%
%PyPy follows a different approach from the previously presented \VM generation frameworks.
%For instance, in Squeak and Jikes the final \VM implementation is not much different from an implementation done directly in a low-level language.
%The programmer specifies all the components of the \VM explicitly, either by implementing them directly or using a provided library.
%Compared to the more static C and C++ these \VM generation frameworks make the compilation phase more tangible.
%Smalltalk in Squeak or Java in Jikes or Maxine fulfill the purpose of the template system in C++ or the restricted macro system in C.
%For the explicit implementation part PyPy is no different.
%However, certain features for the final \VM are directly absorbed from the underlying PyPy infrastructure.
%For instance, the JIT support or the GC are not explicitly implemented but provided by the PyPy framework itself.
%This is a big difference to the other \VM frameworks as it allows programmers to write the \VM in a more high-level fashion.
%For instance in Squeak memory allocation, even for \VM-level objects, has to be performed explicitly.
%Whereas in PyPy the garbage collection is left to the underlying \VM building infrastructure.
%This approach allows RPython \VMs to behave like standard Python programs.
%
%Much like the automatic memory management, PyPy provides a tracing JIT generator~\cite{Bolz09a}.
%By default the \VM programmer does not write an explicit JIT in PyPy.
%Instead the \VM code is annotated to guide the underlying tracing JIT generator.
%This means a \VM compilation time a specific tracing JIT is created for the given meta information.
%As a result, the JIT can track high-level loops in the final interpreted language.
%Again, this is similar to PyPy's GC, both are provided as a service and do not have to be programmed explicitly.
%Instead, the \VM programmer tweaks parameters of the JIT or GC.

% ------------------------------------------------------------------------------
%\subsection*{\textsc{Pinocchio \VM}}
%\seclabel{background-Pinocchio }
%
%Pinocchio~\cite{Verw11a} is a research Smalltalk environment that directly uses native code instead of bytecodes.
%The only execution base is native code which is directly generated by the language-side compiler.
%
%Pinocchio is built from a kernel derived originally from a \PH image.
%For the bootstrap classes, objects and methods are exported into binary, native images and linked together with a standard C linker to a final executable.
%For simplicity it relies on a very small part of C code to provide essential primitives, for instance used for file handling.
%Additionally it specifies part of the bootstrap for the Smalltalk object model in plain C code.
%However, besides that, all the other code is written and developed directly in Smalltalk.
%
%An important aspect of Pinocchio is that the method lookup is expressed in terms of normal Smalltalk code.
%Typically this code statically resides in the \VM, thus at a different meta-level.
%Hence this implies for most systems that the lookup can not be modified without altering the \VM itself.
%However, expressing the lookup in terms for normal language-side code introduces a recursive dependency during the bootstrap.
%In order to run the lookup code expressed in Smalltalk code, we have to perform message sends.
%These, in return, require an already working lookup mechanism.
%Hence, without taking special care, a language-side lookup method will lead to infinite recursion during startup.
%Pinocchio resolves this problem by directly interacting with the low-level execution format which among other things relies on inline caches to improve performance.
%The important property of inline caches is that they bypass the slow language-side lookup by directly jumping to the last activated method at a send-site.
%This is exactly the behavior we need to prevent recursion during the startup.
%Hence, when generating the native code for the bootstrap, it prefills all the inline caches of the methods required to perform a full method lookup.
%As a result, when at runtime it is required the first real method lookup, the lookup code itself is running perfectly on the prefilled inline caches.
%Pinocchio achieves a flexible connection between the low-level world and the high-level language-side.
%During execution, the \VM jumps freely between what previously was native \VM-level code and interpretation of language-side code.

% ------------------------------------------------------------------------------
\subsection*{\textsc{Klein \VM}}
\seclabel{background-klein}

\urlfootnote{Klein}{http://kleinvm.sourceforge.net/} is a metacircular \VM for the Self programming language that has no separation into \VM and language \cite{Unga05a}.
A main difference between Klein and the already seen metacircular \VM projects is that the reification of the \VM-level elements survives the code generation or compilation time.
Instead the \VM structures are exposed to the language as Self objects, exposing them to the language and thus allowing their manipulation from the application runtime.
%Hence the Klein \VM supports true \VM-level reflection since there is only a single code base.

Additionally to the advances in reflection and metacircularity, Klein focuses on fast compilation turnarounds to allow for a responsive development process.
Which is unlike for instance the Squeak \VM where a full \VM bootstrap takes an order of minutes on modern hardware.
Klein also supports advanced mirror-based debugging tools to inspect and modify a remote \VM.

Development on the Klein \VM stopped in 2009 and left the Klein \VM in fairly usable state.
Yet, it proved that it is possible and build a language-runtime without the classical separation of the language-side and the \VM.
From the literature presented about the Klein project we see a strong focus on the improvements of the development tools.
%The fact that the language-runtime allows \VM-level reflection to change the \VM dynamically is not directly mentioned in the literature.
%While we see the practical limitations of changing the \VM runtime system at runtime we would like to open the doors to this new form of reflection.

\section{Language Virtualization Techniques}\label{sec:background_virtualization_techniques}

The most related family of work in virtualization are approaches like Xen~\cite{Chis07a}. Xen is a Virtual Machine Monitor~(VMM) that allows one to control and manage \VM in a high performance and resource-managed way. This approach targets the virtualization of full and unmodified operating systems, to facilitate their adoption in industrial/productive environments. They rely on support from the hardware platform, and in some cases from the guest OS, concentrating themselves on performance and production features.

Operating System virtualization technology is characterized by the existence of an \emph{hypervisor}~(named after the Operating System \emph{supervisor} that controls the OS processes). The hypervisor is the \VM component that allows one to observe or control the internals of one or many \VMs. A \VM hypervisor gives us, amongst others, the following services:

\begin{description}
\item[Co-location.] Co-location is the ability to have co-existing applications on top of the same virtual machine. With co-location, a single \VM has information about all the applications running on top of itself and can integrate that information in its decision process. Additionally, it gives to co-located applications a cheap communication mechanism as they reside in the same operating system process.
\item[Resource control.] \VMs should control how the different resources of their applications are used. However, state of the art \VMs do only control their consumed memory with the usage of a memory manager. They do not perform in general any control in other kind of resources such as CPU or energy consumption.
\item[Security.] \VMs should control how applications access sensible information such as files and network connections or execute potentially dangerous operations such as system calls.
\item[Application mobility.] As applications are portable, they should be easily migrated between different \VMs also at runtime. Application mobility provides support for resource re-allocation.
\end{description}

High-level languages abstract the developer from the complexities of the underlying machine by running on top of a language \VM. A language \VM provides a language with an execution model closer to its semantics as well as several services such as automatic memory management or cross-cutting optimizations. Language \VMs also provide with portability \ie a program can run on different operating systems and hardware architectures because the \VM abstracts it from the underlying particular details. Although these language \VMs are indeed \emph{Virtual}, state of the art production-ready \VMs do not provide by themselves with the typical advantages of virtualized operating systems such as co-location, resource control, mature security or application mobility support.

With the objective of doing application runtime manipulation, we study in the following sections techniques that to our understanding are virtualization-related techniques applied to application runtimes: application co-existence~(Section \ref{sec:virtualization_coexistence}) and application manipulation~(Section \ref{sec:virtualization_control}). Finally, we conclude by presenting the aspects of these solutions that inspired our solution following in the next chapters.%We divide theses works in two main topics that are of interest for us in the subject of runtime manipulation. First, we present related work that targets co-location of language runtimes on the same \VM. We continue this section by presenting related work on the subject of runtime control.

\subsection{Application Co-existence}\label{sec:virtualization_coexistence}

\subsubsection*{\textsc{Class Loaders}}
In Java, classes are loaded dynamically through a class loader~\cite{Lian98a}. A class loader is a first-class entity responsible of loading classes: create their runtime representation, loading their methods and linking their class references. A class loader remembers all classes it loaded, and it is responsible for loading all classes related to  them. Class loaders define namespaces: different class loaders can load classes with the same name. These classes will be isolated in the sense that they will not be visible to the others statically.

Class loaders can be specialized and extended to provide custom behavior. For example, Fong et. al.~\cite{Fong10a} use the class loading mechanism to enforce scoping rules and determine the visibility of names in various region of the program. They allow the user to control untrusted
namespaces and classes and they have defined a language to define security policy. Jensen et. al.~\cite{Jens98a} provide a formalization of the class loader with the means to enforce security. They also use a bytecode verifier on class loading to check if a class' bytecode doesn't try to perform overflow or underflow operations.

In the context of this thesis, we consider the class loader isolation mechanism as it can be used for application co-existence. Different versions of the same application can be loaded by different class loaders and be running at the same time. Class loaders present however a main limitation on the so called \emph{bootstrap class loader}: the literature does not explore the means to load~(and use) different versions of the main runtime classes of the language. Moreover, Java's bootstrap class loader is often implemented natively, and as such, we have no control on it from the language.

Notice additionally that class loaders provide only a load mechanism. Once we loaded several versions of the same application, it does not support the means to manage changes or updates of these applications. In this regard, the OSGI~\cite{OSGI} architecture implementations do often make use of class loaders to load classes into separately isolated components and manage them in a higher level way.

\subsubsection*{\textsc{Changeboxes}}

Changeboxes~\cite{Denk07c} is a change model designed to encapsulate and scope changes. Its main purpose is to allow several versions of a system to co-exist at runtime \ie the existence in the same environment of different versions of the same classes and methods. In changeboxes, a \emph{changebox} is a first-class entity that encapsulates changes made on the language elements~(\eg classes and methods) and an executable version of the system with its changes applied. The system can contain many changeboxes at the same time, and applications can be scoped to run within different changeboxes. This notion of dynamically scoping an application to a changebox allows one to have co-existing environments~(\eg testing, development, production), increasing the developer's efficiency. Furthermore, it eases application update and migration to new versions, and reduces its update down-time as the application does not have to be stopped to be updated.

A Changeboxes prototype was developed in Smalltalk and its scoping mechanisms were implemented as follows:

\begin{description}
\item[Message send interception.] Message sends can activate different methods, within different changeboxes. A MethodWrapper~\cite{Bran98a} is placed instead of the method that has multiple versions, and it delegates the execution to the method that corresponds to the currently valid changebox.

\item[Class access interception.] Smalltalk resolves class names at compile time, inserting a reference to the given class inside the method's literal array. However, accessing a class should yield different class objects if the changebox contains a different version of it. To resolve this, class accesses affected by a changebox are postponed until runtime, and the code is recompiled in such a way: instead of putting the class inside the literal array, the class is dynamically looked-up from the class table when it is accessed.
\end{description}

Changeboxes model proves sound to update and migrate application and framework classes. However, it has the main drawback of not affecting critical classes in the system. Changeboxes prototype does not work on classes such as \ct{Array} or \ct{CompiledMethod} as the underlying infrastructure~(the VM) restricts the system to the existence of only one of them at the same time. The changes model does not provide neither a solution for this problem, as it focuses on application code update, leaving this as an open problem.

\subsubsection*{\textsc{Caja\textbackslash Cajita} - Object Capability Languages}

Caja~\cite{Mill08a} is an object-capability language~\cite{Levy84a,Mill03a,Spoo00a} subset of Javascript with the objective of bringing script isolation in Javascript. Caja was thought in the context of the web, where untrusted scripts can be loaded in any webpage and profit from any data available in the webpage. Caja defines a safe Javascript subset that removes elements from the language such as \ct{with} or \ct{eval} because their semantics are strange and in some cases unpredictable. Caja includes Cajita, a subset of Caja without the \ct{this} keyword. Caja is meant for transforming and migrating already existing Javascript code, while Cajita is meant for newly written code.

Caja works with a combination of static and dynamic techniques. First, a static verifier checks and transforms Caja code into sanitized Javascript. This sanitized Javascript contains runtime checks that complements the static verifications. All thee changes are meant to avoid exploits and vulnerabilities from untrusted sources. Caja also adds some new features to the Javascript libraries with support to freeze objects and turn them immutable. 

To allow the safe co-existence of several scripts, Caja removes the Javascript global environment and replaces it by modules. Caja Modules co-exist transparently and can only access each other's data through an explicit and verified interface.
%
%\subsubsection*{\textsc{Worlds}}
%Worlds~\cite{Wart08a} provide a way to control and scope side-effects in Javascript. Side-effects are limited to a first-class environment.

%\subsubsection*{\textsc{Gemstone}}
%Gemstone \cite{Otis91a} provides the concept of class versions. Classes are
%automatically versioned, but existing instances keep the class (shape and
%behavior) of the original definition. Instances can be migrated at any time.
%Gemstone provides (database) transaction semantics, thus state can be rolled
%back should the migration fail.
%Gemstone's class versions extend the usual Smalltalk class evolution mechanism for robustness, 
%large datasets, and domain-specific migration policies. In contrast, ObjectSpaces target general 
%reflective access and bootstrap-like evolutions of code that is critical to the environment.

\subsubsection*{KaffeOS}

KaffeOS~\cite{Back00a} is a multi-application Java Runtime System centered in application isolation and resource accounting. The KaffeOS runtime allows the isolated co-existence of Java applications so they cannot access each other's data, nor interfere in their execution. To avoid the latter, the KaffeOS \VM accounts the application's consumption of CPU and memory.

KaffeOS adds the process abstraction in the Java language, as in the sense of a process for an operating system. Each KaffeOS process owns a separate memory region~(a process heap) where its object's are allocated. Shared objects reside in special shared memory regions. A \emph{kernel heap} makes a distinction between code that runs in user mode or kernel mode. Regarding process communication, cross-process references become cross-heap references and are handled specially by the \VM. Resources are accounted and controlled at the \VM level for each process, so no process starves other processes.

KaffeOS succeeds to make several Java applications to run side by side taking care on hardware resource consumption in addition of application's data. However, this solution is still limited with respect to base language classes. For example, the class \ct{java.lang.Object} must be shared between different processes to allow their communication.

%J-Kernel \cite{Hawb98a} and Luna \cite{Hawb02a} present a solution similar to ours regarding the memory usage. They are Java solution for isolating object graphs with security purposes. In them, each object graph is called a \emph{protection domain}. All protection domains loaded in a system, and their objects, share the same memory space. 
%
%The J-Kernel enforces the separation between domains by using the Java type system, the inability of the Java language to forge object references, and by providing capability objects\cite{Levy84a,Mill03a,Spoo00a} enabling remote messaging and controlling the communication. This same separation in Luna \cite{Hawb02a} is achieved by the modification of the type system and the addition in the virtual machine of the \emph{remote reference} concept.

\subsection{Application Manipulation}\label{sec:virtualization_control}

\subsubsection*{JVMTI}
The Java Virtual Machine Tool Interface~(JVMTI)~\cite{JVMPI} is the interface offered by the Java \VM for its manipulation and control. Originally called Java Platform Debugger Architecture~(JPDA) and used in the context of debugging, it was extended to support other use cases such as monitoring and profiling.

JVMTI exposes C functions to manipulate a Java VM~(Figure \ref{fig:jvmti}). The JVMTI client, so called an \emph{Agent}, queries and controls the given JVM through this interface. The manipulated JVM and an agent share the same operating system process. JVMTI agents are meant to be written in C, to be as compact as possible and allow maximal control with minimal intrusion.

\begin{figure}[ht]
\begin{center}
\includegraphics[width=.9\linewidth]{jvmti}
\caption{\textbf{JVMTI Architecture.} An agent controls a JVM though JVMTI. Both share the same operating system process.\label{fig:jvmti}}
\end{center}
\end{figure}

JVMTI provides with introspection and some limited intercession facilities at VM and language level. In particular it provides with memory and heap management, thread control, execution stack manipulation, object and class manipulation and breakpoint support. JVMTI is used mainly with the purpose of debugging, monitoring and analysis, particularly profiling and thread analysis.

In the context of this thesis, we identify in JVMTI's architecture a similarity to a virtualization system. While the Java \VM takes the place of a the virtualized operating system and the agent is its hypervisor and can control.

\subsubsection*{MVM: a Multi User Virtual Machine}
The Multi-user Virtual Machine~\cite{Czaj03a,Czaj01a} is a general purpose virtual machine for the Java language that allows the co-existence of different applications, potentially from different users. Each application running on top of the MVM is an \emph{isolate} based on the Java Application Isolation API specification~\cite{JSR121}. This Java Application Isolation API defines a uniform mechanism to control the life-cycle of Java applications.

Many isolates co-exist not interfering each other, as they believe they own their private JVM: the runtime is modified, so state is not shared between them by default. MVM allows several communication mechanisms to securely communicate isolates: from standard mechanisms such as sockets, up to \emph{links}, a low-level isolate-to-isolate mechanism introduced by the Isolate API.

MVM can run unmodified Java applications. Additionally, MVM-aware applications can use the API it provides to control the life-cycle~(\eg creation, suspension, resuming and and termination) and the available resources of other isolates. Notice that differently from JVMTI, this control API is available to the applications running on the JVM and not only to native agents.

%\subsection*{Java Isolates}
%Java Isolates \cite{JSR121} allow multiple applications to run inside the same Java virtual machine.
%Nothing is shared between the different applications. Resources like CPU time, memory are controlled 
%and restricted. Isolates can communicate through channel, since nothing is shared the data are copied. 
%Java Isolates are defined in the Java Specification Request 121, but no commercials Java virtual 
%machine implement the specification.

% =============================================================================

\section{Conclusion and Summary}

In this chapter we studied the state of the art on application runtime manipulation techniques. We focus this study on three main problems: the flexibility to change an application and language runtime, the mixture of low-level and high-level concerns and the tool support to do it.

First, we saw that available production \VMs do not offer with the flexibility to modify nor the language nor the application runtime. These \VMs usually fix their how their language runtimes are initialized and enforce a language model to their users. Additionally, they tend to mix \VM concerns such as memory management or JIT compilation with the code in charge of managing the application runtime.

Different reflection models such as the ones appearing in LISP, Smalltalk or Ruby provide with the \emph{flexibility} to manipulate an application runtime from the runtime itself once it is already up un running. However, there exists trade offs between a usable reflection model and the safety of using it to modify its own definition.

Metacircular \VMs explore the idea of expressing a \VM in the same language it supports at the end, under the principles of \emph{high-level low-level programming}. High-level low-level programming aim to provide with \emph{better tool support} and a smaller mismatch to \VM development, with the main objective of increasing the efficiency of \VM developers. Some of the more sophisticated \VMs, like Klein, reifies and exposes its internal components, allowing one to modify them from the running application runtime.

Finally, virtualization techniques applied to application runtimes provide with application co-existence and application runtime control. Application co-existence is used mainly with isolation purposes, but it could be used also to allow a \emph{high-level interaction and control} between applications, as in MVM. JVMTI on the other side, provides with application runtime control and manipulation with a low-level API.

% =============================================================================
% =============================================================================
% =============================================================================

\chapter{Application Tailoring}
\chaplabel{state_tailoring}
\minitoc

In the context of this thesis, we explore application tailoring as one usage of an application runtime, in the context limited infrastructure devices~(either hardware or software).
Application tailoring allows the specialization of an application for its deployment in constrained devices.
This chapter starts by identifying the problem that motivates application tailoring: code bloat~(Section \ref{sec:footprint_problems}). Code bloat is mainly caused by unused code units appearing in general purpose libraries.
We illustrate this problem through an example.

Existing application extraction or \emph{Tailoring} techniques build deployment artifacts containing a subset of the original code units inside an application. However, existing tailoring techniques are not completely efficient because they have to overcome many different challenges such as reflection or the absence of type annotations~(Section \ref{sec:challenges}). We present an evaluation criteria that allows us to compare this different existing solutions~(Section \ref{sec:tailoring_criteria}).

Finally, this chapter concludes by presenting and comparing this techniques, grouped in four different categories: 
\begin{description}
\item[Dedicated platforms.] Pre-built tailored platforms with specialized \VMs and language runtimes~(Section \ref{section:static_selection_rw}).
\item[Static techniques.] Tailoring techniques that depend only in static program information such as the source code and type annotations~(Section \ref{section:static_rw}).
\item[Dynamic techniques.] Tailoring techniques that make use only of runtime information~(Section \ref{section:dynamic_rw}).
\item[Hybrid techniques.] Tailoring techniques that complement both dynamic and static techniques~(Section \ref{section:hybrid_rw}).
\end{description}


\section{Problems of Constrained Devices Deployment}\label{sec:footprint_problems}
Deployed object-oriented applications often contain \emph{code units}~(e.g. packages, classes, methods) that the running application never uses.
This problem shows itself more evident and harder to control under the usage of third party software. 
Third party libraries and frameworks are designed in a generic fashion that allows multiple usages and functionalities, while applications use only few of them. 
Examples are logging libraries, web application frameworks or object-relational mappers.

Unused deployed code units have an undesired impact when targeting a constrained infrastructure. 
Constrained devices may constrain applications due to a restrictive hardware such as low primary or secondary memory~\cite{Mart12a}, or even software impositions such as the Android's Dalvik VM restriction to deploy only 65536 methods\footnote{According to dalvik's bytecode documentation~(\url{http://source.android.com/devices/tech/dalvik/dalvik-bytecode.html}), the source register accepts values between 0 and 65535.}. Big JavaScript mashup applications have an impact on loading time due to network speed and parsing time.
These limitations may forbid the deployment of applications that contain lots of code units, or limit the amount of applications and content a user can have in its device.

Existing solutions to this problem propose to eliminate dead code by extracting used code units of an application, and thus reduce their size and memory footprint. The majority of the solutions in the field propose to automatically detect and extract used code units, so called \emph{tailoring}, with static call graph construction as the most dominant technique~\cite{Grov97a}. 
These static approaches present limitations in the presence of dynamic features such as reflection~\cite{Livs05a}, or in the absence of static type annotations. Additionally, they do not allow the user to customize the process of selection to cover different levels of an application's code \ie a user may want to extract only the used application specific code and let third-party and base-language libraries untouched; another user may want apply the process to the whole of the application.


%\section{A Motivating Example} \label{sec:example_intro}

To clearly show the problem, consider the application using a logging library in Figure~\ref{fig:example_dead_code}. In this figure, we emphasize in gray the unused code units that can safely be removed.
%An interface is present in the diagram to show polymorphism between two classes that do not share a class inheritance hierarchy. 
%However, some languages, such as the dynamically typed ones, may not need to represent it in the source code.

\begin{figure}[ht]
\begin{center}
\includegraphics[width=.7\linewidth]{example_dead_code}
\caption{\small\textbf{Example of unused code units.} In gray, the unused code units that can safely be removed.\label{fig:example_dead_code}}
\end{center}
\end{figure}

Figure~\ref{fig:code_example1} shows the code of this application, written in the Pharo Smalltalk language. This application contains a \ct{MainApp} class with a \ct{start} method, which is the entry point of our application. The \ct{start} method creates an instance of \ct{Stdout\-Logger} and logs the application's start and end. In turn, the \ct{StdoutLogger} uses the \ct{stdout} global instance to log in the standard output the current time and the message. To print the time, the \ct{StdoutLogger} makes use of the \ct{Time} class from the base libraries of the language. Note that for the sake of clarity, we didn't include in the example all base libraries, though, in modern programming languages they represent a large codebase with several features going from networking to multithreading. For example, Java 8 SE contains 4240 classes\footnote{according to the javadoc API}, and the development edition of Pharo 3.0~\cite{Blac09a} contains 4115 classes and traits.

\begin{figure}[ht]
\begin{code}
MainApp>>start (
    logger := StdoutLogger new.
    logger log: 'Application has started'.
    "do something"
    logger log: 'Application has finished'. )

!\unusedcode{StdoutLogger>>newLine (}!
!\unusedcode{~~~stdout newLine. )}!

StdoutLogger>>log: aMessage (
    stdout nextPutAll: Time now printString.
    stdout nextPutAll: aMessage.
    stdout newLine. )
    
!\unusedcode{RemoteLogger>>log: aMessage (}!
!\unusedcode{~~~| socket |}!
!\unusedcode{~~~socket := self newSocket.}!
!\unusedcode{~~~socket nextPutAll: Time now printString.}!
!\unusedcode{~~~socket nextPutAll: aMessage.}!
!\unusedcode{~~~socket newLine. )}!

!\unusedcode{RemoteLogger>>newSocket (}!
!\unusedcode{~~~"...."}!
!\unusedcode{~~~"creates an instance of socket given some configuration" )}!
\end{code}

\caption{ \small\textbf{Code of the example logging application.} In gray, methods not used by the application.\label{fig:code_example1}}
\end{figure}

In this example we can detect the following unused code units, shown in grey in Figure~\ref{fig:example_dead_code} and Figure~\ref{fig:code_example1}:
\begin{enumerate}
\item The logger library includes two logging classes~(\ct{Stdout\-Logger} and \ct{RemoteLogger}). Only the \ct{StdoutLogger} is used and thus, the \ct{RemoteLogger} class can be discarded.
\item Since the \ct{MainApp} class does not use the \ct{Socket} class nor the \ct{RemoteLogger} class~(the only user of the \ct{Socket} class), the \ct{Socket} class can be discarded.
\item No class in the application makes use of the \ct{Date} class, according that it is not used in the base libs either. Then, this class can be safely removed.
\item The method \ct{newLine}~(lines 7-8 of Figure~\ref{fig:code_example1}) of the \ct{StdoutLogger} class is not used and can be also removed.
\item The \ct{StdoutLogger} class uses the \ct{Time} class to print the current time. Then, all code units that are not related to the \ct{Time now} resolution or printing~(\ie time arithmetic) could be considered as unused.
\end{enumerate}

We would like to generate a new version of this application not containing these unused code units while keeping the application's behavior. We call this technique \emph{application tailoring}.

\section{Challenges of Application Tailoring} \label{sec:challenges}

A lot of work exists on the tailoring of statically-typed applications~\cite{Cour10a,Rays02a,Tip03a,Popa04a,Teod01a}, where type annotations aid in the resolution of which piece of code will be used at runtime. 
However, static analysis is not an option in the context of dynamically-typed languages or in the presence of meta-programming and reflection~\cite{Livs05a}.
%~\cite{Mart12a}
In this context of dynamically-typed and object-oriented programs that may use reflection, we identify the following main challenges in creating tailored applications:

\begin{description}

\item[Language Runtime Unused Code Units.] As the core point of this thesis, we would like to extract not only application code but also code that belongs to the language base libraries, including its core meta-model.

\item[Dynamic typing.] Dynamically-typed languages cannot benefit from the most powerful static analysis due to the absence of type annotations. Name-based static analyses~(static analyses that build a simpler call graph based only on method names) can be used on them, but are not as efficient. Static techniques to detect code unit usage, such as call-graph analysis, need the support of more dynamic techniques \eg tracking runtime information, following the application's execution flow, or performing symbolic execution.

\item[Polymorphism and inheritance.] Polymorphism in object-oriented languages allows a code unit to treat objects of different concrete types in the same way as soon as they share a common interface. Inheritance plays a similar role: any class can extend another class and provide different behavior while sharing a common API.
As a consequence, both polymorphism and inheritance make the behavior of a program more difficult to predict by just statically analyzing its code units~\cite{Taen89a}.

\item[Application runtime configuration.] Modern applications often contain libraries and frameworks besides their proper code. 
To make these different code units fit together, applications rely on heavy configurations. 
These configurations are usually present in configuration files looked up dynamically by the application. 
Based on these configurations, the dependency injection pattern is usually used to dynamically set up the application. 
This recurrent and standard process for configuring applications implies that static analysis will be inefficient to detect used code units without library-specific knowledge.

\item[Reflection.] Reflection makes static analysis inoperative by allowing an application to execute unanticipated pieces of code. 
Any \ct{String} resulting from a program execution or program configuration can denote a message send\footnote{We refer method invocations as message sends because they represent better from our understanding the dynamic property of the invocation.}, the name of a class to be instantiated, or even a script to be executed. Reflection is indeed important to cover, since it is a broadly used tool in industrial applications with object relational mappers such as Hibernate or Glorp and web frameworks such as Ruby On Rails, Struts or Seaside.
\end{description}

\section{Evaluation Criteria}\label{sec:tailoring_criteria}

This section presents properties that we consider the most relevant to evaluate techniques addressing the issue of unused deployment code units.

\begin{description}

\item[Reflection.] An ideal tailoring solution should handle correctly reflective code and resolve the unanticipated code executions in the same way as the application would do during runtime.

\item[Base Library Specialization.] A programming language contains several base libraries covering very common and generic tasks. Not all the code units in these libraries are used in an application. An ideal tailoring solution should tailor base libraries of the language to reduce an application's deployment memory footprint.

\item[Third Party Libraries Specialization.] Applications use several third-party libraries and frameworks covering several aspects of application development such as user interfaces, persistence or publication of services. Third party libraries contain large code bases and many dependencies. Thus, an ideal tailoring solution should consider the existence of third-party software.

\item[Legacy Code.] An ideal tailoring solution should be applicable on already existing applications and not require modifications on them.

\item[Dedicated Infrastructure for Deployment.] An ideal tailoring solution should produce a version of the application that is able to run on the official production infrastructure~(such as the VM) without overhead.

\item[Flexibility.] An ideal solution for tailoring an application should support many different levels of application. Some applications may not need to tailor base libraries because they are shared with other applications. However, tailoring base libraries may be useful on those applications residing alone in constrained devices.

\item[Applicable without type annotations.] An ideal tailoring solution should be applicable to dynamic languages with no type annotations.

\item[Full Coverage.] An ideal tailoring solution will guarantee that all code units selected as part of the deployable application are those needed. That is, it does not contain extra code units, nor it misses code units.

\end{description}

%The reduction of the deployment footprint of object-oriented applications has been subject of interest both in industry and research since many years. In such regard, we identified four different families of solutions for dead code elimination: dedicated platforms~(cf. Section \ref{section:static_selection_rw}), static analyses~(cf. Section \ref{section:static_rw}), dynamic analyses~(cf. Section \ref{section:dynamic_rw}) and hybrid analyses~(cf. Section \ref{section:hybrid_rw}).

\section{Dedicated platforms}%Pre-conceived specialized application-independent platforms}
\label{section:static_selection_rw}

Dedicated platforms are platforms containing frameworks and/or libraries prepared to run under specific circumstances. For example, Java Micro Edition~(J2ME)~\cite{JavaME} as the dedicated version of the Java platform, or Cocoa Touch as the one of Cocoa. These specialized platforms are reduced platforms to run applications inside mobile and constrained devices. These platforms provide a reduced and fixed set of base libraries defined a priori and in a not customizable way. Applications have to be written especially for them, and thus legacy code and third-party libraries not written especially for it are not compatible. Reflection is available since the statically tailored base libraries are built in a not automatic fashion, and the application code is not tailored.

\section{Static Analysis-Based Techniques}\label{section:static_rw}

Static analysis approaches for dead code elimination make use of the static information of a program to select the minimal subset of used elements. The bibliography describes four different algorithms to achieve this goal: unique name, class hierarchy analysis~(CHA), rapid type analysis~(RTA) and reachable members analysis~(RMA) \cite{Baco96a, Titz06a}. These techniques share a common approach, selecting an entry point method of an application and following from it the execution flow using the available static information \ie type annotations, and class and method names, building a call-graph~\cite{Grov97a}.

These techniques have been studied and applied in many environments and languages. Rayside et al.~\cite{Rays02a}, Jax~\cite{Tip03a} and the ExoVM System~\cite{Titz06a} propose application extraction tools using these techniques for Java applications. Sallenave et al.~\cite{Sall10a} apply RTA to produce smaller .NET assemblies for embedded systems. Bournoutian et al.~\cite{Bour14a} use CHA to optimize on-device Objective-C applications. Ole Agesen~\cite{Ages96a} presents in his thesis a static technique applied to Self, a dynamically-typed language. Ole Agesen uses type inference to obtain type information and use it to select which objects to extract.

In summary, these approaches are based on the static types found either in the source code or byte code. Thus, they are not applicable \emph{efficiently} in dynamic languages with no static type declarations. These solutions are valuable as they allow one to tailor base and third-party libraries, and legacy code. Their tailoring approach generates new deployment units that can run on the standard runtime infrastructure. The main drawback of this approach appears in the presence of reflection and configuration files, which will only work with a subset of reflective invocations through complementary analyses on the strings found in the source code. Also, existing solutions in this family lack the flexibility to declare and identify levels of tailoring, making it an "all or nothing".

\section{Dynamic Analysis-Based Techniques}\label{section:dynamic_rw}

Dynamic analysis techniques use exclusively runtime information~(\ie execution flow, alive objects, execution statistics) to perform dead code elimination. Amongst these, we identify two different approaches: \emph{load on demand} and \emph{code collection}. Load on demand approaches detect during runtime whenever a class or method needs to be installed and request it to a server application. Code collection approaches deploy the full application  and garbage collect unused code based on usage statistics. Related work in this family share a common characteristic: these techniques are used inside ubiquitous systems \ie systems meant to be always connected. Ubiquitous systems, as they are always connected, have a possibility to fallback and recover in the case of incompleteness. However, to focus here on the dead code elimination techniques, we will discuss the incompleteness recovery techniques in section \ref{sec:discussion}.

\begin{description}
\item[JUCE \cite{Popa04a,Teod01a}.] It is a platform for ubiquitous devices supporting code load on demand and code collection. Its approach for building up an application is similar to Tornado. First, it initializes a minimal running application and code is loaded, with a method granularity, from a server located in a different machine. Unused code is collected following usage statistics, and loaded back again on demand if needed.

\item[OLIE~\cite{Gu03a}.] It is an engine that intelligently partitions and offloads objects during runtime to minimize memory consumption. It is part of the adaptive infrastructure for distributed loading (AIDE). In OLIE, offloaded objects are indeed migrated to nearby remote devices. Migrated objects can be accessed later through proxies that perform remote invocations on them.

\item[SlimVM~\cite{Kers09a, Wagn11a}.] It is an ubiquitous system where all code resides on a remote server and is loaded only on demand on small devices. Some static analysis is performed only on the server to reduce the size of the transported code, by identifying most likely needed code. SlimVM changes the class format. However, on the client side, every code load is done dynamically.

\end{description}

All solutions inside this category share one main property: they require to run the application inside a dedicated infrastructure to apply their techniques \eg dedicated VMs implementing remote lazy loading, code collection or new bytecode sets. The main challenge of these solutions resides on applying these techniques while minimizing their impact on performance during the runtime. Additionally, these solutions require their applications to run exclusively inside their infrastructure. Tornado works in the same way as these solutions: it uses a dedicated infrastructure to run the desired application and select the used elements.  However, Tornado provides also with the ability to extract this application and run in \emph{offline} mode, using the non-modified infrastructure.

Regarding dynamic features such as reflection, these solutions are the ones that can, potentially, handle it in the best way since they have in runtime all the information needed to resolve it. JUCE and OLIE, as Tornado, handle naturally reflection as they do not change the runtime representation (which programs make assumptions of, when they use metaprogramming). SlimVM on the other side, had to change the reflection support because they changed the object and class representation on their VM.

Regarding its applicability, SlimVM needs to recompile the whole application into its own format, while OLIE and JUCE, as Tornado, can tailor base and third party libraries without any modifications on it. Thus, the latter two can be applied to legacy code also for free. None of these solutions provide with the ability to select the level of tailoring always working on the full application. In contrast, Tornado uses seeds to force a minimal subset of elements to be part of the application.


\section{Hybrid Analysis-Based Techniques}\label{section:hybrid_rw}

Hybrid analysis techniques mix static and dynamic~(\ie runtime) information to provide better results. The common approach of these is to start an application, such as Tornado does, and pause it after some minimal runtime information is available \ie call stacks are created, some classes are loaded and initialized, and some objects are instantiated. Then, it uses the built stack of alive objects to perform a static analysis, as described in Section \ref{section:static_rw}, with concrete type information.

Java in The Small (JITS)~\cite{Cour10a} uses a hybrid approach to select the used parts of a program, and then loads them inside a binary image. A dedicated VM loads the binary image at startup. JITS's approach tailors base and third-party libraries as well as application specific code. It does not require modifications on the existent application to tailor it, so a legacy application could theoretically be tailored with this approach. JITS does not offer the possibility to configure the tailoring level, since it was designed to be used only in embedded devices where no more than one application would be running. Regarding reflection, JITS presents the same drawbacks as the other static call graph analysis approaches since not all the runtime information about the reflective invocations can be deduced.

\section{Conclusion and Summary}

Tailoring is a cross-cutting technique that may affect any element of an application runtime, and thus, it requires particular support to detect and extract used code units at runtime. Several existing techniques were applied in the past with several results.
Table~\ref{tb:comparison_intro} presents a comparison of these techniques, given the criteria we defined in Section~\ref{sec:tailoring_criteria}.
We can see an almost general lack of support of dynamic techniques such as reflection and the flexibility to select whether a code unit should be subject to the tailoring or not. \chapref{chap:rfg} explores a new dynamic tailoring technique based on \Vtt. We show how our technique succeeds to tailor even in the existence of reflection and allows flexibility while others do not.

\begin{table}[ht]
 \small
 	\centering
 	\begin{tabular}{|c|cccc|}
	
\hline
 			& \textbf{Dedicated}
 			& \textbf{Static}
			& \textbf{Hybrid}
 			& \textbf{Dynamic} \\
 			& \textbf{platforms}
 			& \textbf{Analysis}
			& \textbf{Analysis}
 			& \textbf{Analysis}\\
  \cmidrule(r){2-5}
% \midrule

		Base Libraries
 			& + & + & + & +\\
		\hline
		Third-Party
		& & & & \\Libraries
 			& - & + & + & +\\
		\hline
		Legacy Code
 			& - & + & + & + \\
		\hline
		Reflection Support
 			& + & - & - & + \\
		\hline
		Dedicated Deploy
			& & & & \\
		Infrastructure
 			& - & + & - & -  \\
		\hline
		Flexibility
 			& - & - & - & -   \\
		\hline
		Ensures
		& & & & \\
		Completeness
 			& - & - & - & - \\
 	 \hline
 	\end{tabular}
	\includegraphics[width=.9\linewidth]{criteria_overview}
 	\caption{Evaluation criteria applied to related work on deployment code unit tailoring techniques}
 	\label{tb:comparison_intro}
 \end{table}

\input{chapter-footer.tex}